{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Prediction of Energy Comsumption From Temperature**\n",
        "## By Zichen Liu"
      ],
      "metadata": {
        "id": "ZMkAAH_vlE6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4Xc4MeUArAdf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the files"
      ],
      "metadata": {
        "id": "a3rekGVblAj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "fw-7i9qwrUE6",
        "outputId": "006df1de-c53a-414d-ceb8-cd35ffeb8cd0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88b0f541-b09d-4e71-8568-de755ba3f275\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88b0f541-b09d-4e71-8568-de755ba3f275\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_OHfGbdvtUEj"
      },
      "outputs": [],
      "source": [
        "weather_data = pd.read_csv('weatherstats_toronto_normal_monthly.csv')\n",
        "energy_data = pd.read_excel('UTSG CED CHD FY2019-2023 (1).xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare and clean the data\n",
        "We'll merge the datasets and create a new column indicating whether the consumption is above the baseline."
      ],
      "metadata": {
        "id": "pvbsAK1WmMUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date columns to datetime\n",
        "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
        "energy_data['Month'] = pd.to_datetime(energy_data['Month'])\n",
        "\n",
        "# Identify the date range of the energy data\n",
        "start_date = energy_data['Month'].min()\n",
        "end_date = energy_data['Month'].max()\n",
        "\n",
        "# Filter the weather data to match the date range of the energy data\n",
        "filtered_weather_data = weather_data[(weather_data['date'] >= start_date) & (weather_data['date'] <= end_date)]\n",
        "\n",
        "# Aggregate weather data by month\n",
        "filtered_weather_data['month'] = filtered_weather_data['date'].dt.to_period('M')\n",
        "monthly_weather_data = filtered_weather_data.groupby('month').agg({\n",
        "    'max_temperature_v': 'mean',\n",
        "    'min_temperature_v': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Convert 'month' back to datetime for merging\n",
        "monthly_weather_data['month'] = monthly_weather_data['month'].dt.to_timestamp()\n",
        "\n",
        "# Merge datasets on month\n",
        "merged_data = pd.merge(monthly_weather_data, energy_data, left_on='month', right_on='Month', how='inner')\n",
        "\n",
        "# Calculate baseline consumption for each building\n",
        "baseline_consumption = merged_data.groupby('Archibus Building Name')['Consumption kWh'].transform('mean')\n",
        "\n",
        "# Create a target variable based on whether consumption is above the baseline\n",
        "merged_data['Above_Baseline'] = merged_data['Consumption kWh'] > baseline_consumption\n",
        "\n",
        "# Add temporal feature (month)\n",
        "merged_data['month_number'] = merged_data['month'].dt.month\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noBRfdI4le8i",
        "outputId": "f8424dc3-74b7-4e49-b822-2809d1e92e8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3fa5790e385b>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_weather_data['month'] = filtered_weather_data['date'].dt.to_period('M')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model\n",
        "We'll train a logistic regression model and evaluate its performance."
      ],
      "metadata": {
        "id": "nkXMhWApmYeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns for the model\n",
        "features = merged_data[['max_temperature_v', 'min_temperature_v', 'month_number']]\n",
        "target = merged_data['Above_Baseline']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report_result)\n",
        "print(confusion_matrix_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81_owtLymjV5",
        "outputId": "d5b3a466-f7c1-4d8d-a9f8-774099542b6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.73      0.69       507\n",
            "        True       0.51      0.41      0.45       345\n",
            "\n",
            "    accuracy                           0.60       852\n",
            "   macro avg       0.58      0.57      0.57       852\n",
            "weighted avg       0.59      0.60      0.59       852\n",
            "\n",
            "[[371 136]\n",
            " [205 140]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation\n",
        "**Accuracy: The overall accuracy is 60%.**\n",
        "\n",
        "Precision and Recall for False: The model has a precision of 0.64 and recall of 0.73 for the False class.\n",
        "\n",
        "Precision and Recall for True: The model has a precision of 0.51 and recall of 0.41 for the True class.\n",
        "\n",
        "Confusion Matrix: The model correctly predicted 371 False cases and 140 True cases, but it misclassified 136 False cases as True and 205 True cases as False.\n",
        "\n",
        "The model performs better at predicting the False class than the True class.\n",
        "There is a significant number of True cases being misclassified as False."
      ],
      "metadata": {
        "id": "wKia1noyx2h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reiteration\n",
        "Adding Additional Features and Handling Class Imbalance\n",
        "Let's enhance the feature set and use SMOTE to balance the classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "0UCTxGTgnqBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Add additional weather-related features\n",
        "monthly_weather_data = filtered_weather_data.groupby('month').agg({\n",
        "    'max_temperature_v': 'mean',\n",
        "    'min_temperature_v': 'mean',\n",
        "    'max_relative_humidity_v': 'mean',\n",
        "    'min_relative_humidity_v': 'mean',\n",
        "    'precipitation_v': 'mean',\n",
        "    'rain_v': 'mean',\n",
        "    'snow_v': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Convert 'month' back to datetime for merging\n",
        "monthly_weather_data['month'] = monthly_weather_data['month'].dt.to_timestamp()\n",
        "\n",
        "# Merge datasets on month\n",
        "merged_data = pd.merge(monthly_weather_data, energy_data, left_on='month', right_on='Month', how='inner')\n",
        "\n",
        "# Calculate baseline consumption for each building\n",
        "baseline_consumption = merged_data.groupby('Archibus Building Name')['Consumption kWh'].transform('mean')\n",
        "\n",
        "# Create a target variable based on whether consumption is above the baseline\n",
        "merged_data['Above_Baseline'] = merged_data['Consumption kWh'] > baseline_consumption\n",
        "\n",
        "# Add temporal feature (month)\n",
        "merged_data['month_number'] = merged_data['month'].dt.month\n",
        "\n",
        "# Select relevant columns for the model\n",
        "features = merged_data[['max_temperature_v', 'min_temperature_v', 'max_relative_humidity_v', 'min_relative_humidity_v',\n",
        "                        'precipitation_v', 'rain_v', 'snow_v', 'month_number']]\n",
        "target = merged_data['Above_Baseline']\n",
        "\n",
        "# Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(features, target)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report_result)\n",
        "print(confusion_matrix_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s5tI5irn0DR",
        "outputId": "26f90199-bde8-4e27-9559-c2a1bed39187"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.58      0.65      0.61       484\n",
            "        True       0.61      0.54      0.57       488\n",
            "\n",
            "    accuracy                           0.59       972\n",
            "   macro avg       0.59      0.59      0.59       972\n",
            "weighted avg       0.60      0.59      0.59       972\n",
            "\n",
            "[[314 170]\n",
            " [225 263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretation\n",
        "**Accuracy: The overall accuracy is now 59%.**\n",
        "\n",
        "Precision and Recall for False: Precision is 0.58 and recall is 0.65 for the False class.\n",
        "\n",
        "Precision and Recall for True: Precision is 0.61 and recall is 0.54 for the True class.\n",
        "\n",
        "Balanced Performance: The model shows a more balanced performance between the two classes compared to the previous attempts."
      ],
      "metadata": {
        "id": "jAZyRb0lraG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next steps to fine tune the model"
      ],
      "metadata": {
        "id": "t25IYUiEr7Q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try using a Random Forest classifier and perform hyperparameter tuning to see if we can further improve the performance. This implementation performs hyperparameter tuning using Grid Search to find the optimal parameters for the Random Forest model and evaluates its performance."
      ],
      "metadata": {
        "id": "pdSrk75Ry1lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Perform grid search for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from Grid Search\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the best Random Forest model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report_result)\n",
        "print(confusion_matrix_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBbcitWar6-R",
        "outputId": "2d540d66-cb81-498a-b5e5-951b813e4e0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.71      0.68       484\n",
            "        True       0.68      0.62      0.65       488\n",
            "\n",
            "    accuracy                           0.66       972\n",
            "   macro avg       0.67      0.66      0.66       972\n",
            "weighted avg       0.67      0.66      0.66       972\n",
            "\n",
            "[[342 142]\n",
            " [184 304]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation\n",
        "**Accuracy: The overall accuracy is 66%, which is an improvement from the logistic regression model.**\n",
        "\n",
        "Precision and Recall for False: Precision is 0.65 and recall is 0.71 for the False class.\n",
        "\n",
        "Precision and Recall for True: Precision is 0.68 and recall is 0.62 for the True class.\n",
        "\n",
        "Balanced Performance: The model shows a balanced performance between the two classes."
      ],
      "metadata": {
        "id": "sDB9LXdk0xsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More improvement\n",
        "Use Random Forest, Logistic Regression, and Gradient Boosting classifiers"
      ],
      "metadata": {
        "id": "_N68Z29Y1ID5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances from the Random Forest model\n",
        "importances = best_rf_model.feature_importances_\n",
        "feature_names = features.columns\n",
        "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_importances)\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Initialize the models\n",
        "rf_model = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_split=2, random_state=42)\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Create an ensemble of models\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model),\n",
        "    ('lr', log_reg),\n",
        "    ('gb', gb_model)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report_result)\n",
        "print(confusion_matrix_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDCvEUK9y5wk",
        "outputId": "5d40ef36-e5ac-443b-ef90-fcecd5df3666"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Feature  Importance\n",
            "0        max_temperature_v    0.168323\n",
            "1        min_temperature_v    0.166715\n",
            "2  max_relative_humidity_v    0.147733\n",
            "3  min_relative_humidity_v    0.127357\n",
            "4          precipitation_v    0.115219\n",
            "5                   rain_v    0.114776\n",
            "6                   snow_v    0.093263\n",
            "7             month_number    0.066614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.69      0.68       484\n",
            "        True       0.68      0.66      0.67       488\n",
            "\n",
            "    accuracy                           0.67       972\n",
            "   macro avg       0.67      0.67      0.67       972\n",
            "weighted avg       0.67      0.67      0.67       972\n",
            "\n",
            "[[332 152]\n",
            " [166 322]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation\n",
        "\n",
        "A**ccuracy: The overall accuracy is 67%.**\n",
        "\n",
        "Precision and Recall for False: Precision is 0.\n",
        "67 and recall is 0.69 for the False class.\n",
        "\n",
        "Precision and Recall for True: Precision is 0.68 and recall is 0.66 for the True class.\n",
        "\n",
        "Feature Importance: The most important features are max_temperature_v, min_temperature_v, and max_relative_humidity_v."
      ],
      "metadata": {
        "id": "WN1HTSWh1Wxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further improvement\n",
        "\n",
        "Adding Polynomial and Interaction Features"
      ],
      "metadata": {
        "id": "kzQmATkN1kHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Generate polynomial and interaction features\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
        "X_poly = poly.fit_transform(X_resampled)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the ensemble model with polynomial features\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "classification_report_result_poly = classification_report(y_test, y_pred)\n",
        "confusion_matrix_result_poly = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report_result_poly)\n",
        "print(confusion_matrix_result_poly)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui54UUH81hQh",
        "outputId": "594f5b58-cb38-4395-bc9a-8dd8e631bc04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.65      0.70      0.68       484\n",
            "        True       0.68      0.63      0.65       488\n",
            "\n",
            "    accuracy                           0.67       972\n",
            "   macro avg       0.67      0.67      0.67       972\n",
            "weighted avg       0.67      0.67      0.67       972\n",
            "\n",
            "[[340 144]\n",
            " [181 307]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions (For now)\n",
        "Based on the limited data, I could only reach an accuracy of **67%**. However, with more data and improved models, I am confident that the figure will improve."
      ],
      "metadata": {
        "id": "d-N3NXpo2f-h"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}